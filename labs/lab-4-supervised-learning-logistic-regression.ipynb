{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpath = './data/glass.csv'\n",
    "colnames = ['ri', 'na', 'mg', 'al', 'si', 'k', 'ca', 'ba', 'fe', 'glass_type']\n",
    "df = pd.read_csv(fpath, names=colnames, skiprows=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Dictionary**\n",
    "\n",
    "- `Id`: number: 1 to 214\n",
    "- `RI`: refractive index  \n",
    "- `Na`: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
    "- `Mg`: Magnesium\n",
    "- `Al`: Aluminum\n",
    "- `Si`: Silicon\n",
    "- `K` : Potassium\n",
    "- `Ca`: Calcium\n",
    "- `Ba`: Barium\n",
    "- `Fe`: Iron\n",
    "- `Type` : Type of glass:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's build a regression model for refractice index against aluminum content.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter with regression line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instantiate and fit a linear regression model predicting `ri` from `al` (and an intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression model (name the model \"linreg\").\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add a column `y_pred` to `glass` that stores the model's fitted values for the refractice index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for all values of X and add back to the original DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What do these coefficients mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manually compute the predicted value of `ri` when `al=2.0` using the regression equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute prediction for al=2 using the equation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confirm that this is the same value we would get when using the built-in `.predict()` method of the `LinearRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute prediction for al=2 using the predict method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predicting-a-categorical-response\"></a>\n",
    "## Predicting a Single Categorical Response\n",
    "---\n",
    "\n",
    "Linear regression is appropriate when we want to predict the value of a continuous target/response variable, but what about when we want to predict membership in a class or category?\n",
    "\n",
    "**Examine the glass type column in the data set. What are the counts in each category?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examine glass_type.\n",
    "df.glass_type.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say these types are subdivisions of broader glass types:\n",
    "\n",
    "> **Window glass:** types 1, 2, and 3\n",
    "\n",
    "> **Household glass:** types 5, 6, and 7\n",
    "\n",
    "**Create a new `household` column that indicates whether or not a row is household glass, coded as 1 or 0, respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types 1, 2, 3 are window glass.\n",
    "# Types 5, 6, 7 are household glass.\n",
    "df['household'] = df.glass_type.apply(lambda x: 0 if x in [1, 2, 3] else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.household.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change our task, so that we're predicting the `household` category using `al`. Let's visualize the relationship to figure out how to do this.\n",
    "\n",
    "**Make a scatter plot comparing `al` and `household`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df.plot(kind='scatter', x='al', y='household', ax=ax, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit a new `LinearRegression` predicting `household` from `al`.**\n",
    "\n",
    "Let's draw a regression line like we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit a linear regression model and store the predictions.\n",
    "feature_cols = ['al']\n",
    "X = df[feature_cols] \n",
    "y = df.loc[:, 'household'] \n",
    "linreg.fit(X, y)\n",
    "df['household_pred'] = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot that includes the regression line\n",
    "fig, ax = plt.subplots()\n",
    "df.plot(kind='scatter', x='al', y='household', ax=ax)\n",
    "df.plot(x='al', y='household_pred', color='red', ax=ax, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If **al=3**, what class do we predict for household?\n",
    "\n",
    "If **al=1.5**, what class do we predict for household?\n",
    "\n",
    "We predict the 0 class for **lower** values of al, and the 1 class for **higher** values of al. What's our cutoff value? Around **al=2**, because that's where the linear regression line crosses the midpoint between predicting class 0 and class 1.\n",
    "\n",
    "Therefore, we'll say that if **household_pred >= 0.5**, we predict a class of **1**, else we predict a class of **0**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using this threshold, create a new column of our predictions for whether a row is household glass.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform household_pred to 1 or 0.\n",
    "df['household_pred_class'] = np.where(df.loc[:, 'household_pred'] >= 0.5, 1, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a line that shows our predictions for class membership in household vs. not.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('al', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the class predictions.\n",
    "fig, ax = plt.subplots()\n",
    "df.plot(kind='scatter', x='al', y='household', ax=ax)\n",
    "df.plot(x='al', y='household_pred_class', color='red', ax=ax, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression yields a reasonable binary classifier in this case when we map values above 0.5 to 1 and values below 0.5 to 0.\n",
    "\n",
    "It would be nice if we could also interpret the raw numbers it gives us, such as using probabilities. The problem is that linear regression is **unbounded**. As a result, it gives values below 0 and above 1, which cannot be probabilities.\n",
    "\n",
    "This is where logistic regression comes in: it basically takes that linear regression line and bends its ends into an S-shape so that it always stays between 0 and 1, so that we can interpret its outputs as probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"using-logistic-regression-for-classification\"></a>\n",
    "## Using Logistic Regression for Classification\n",
    "---\n",
    "\n",
    "**Import the `LogisticRegression` class from `linear_model` below and fit the same regression model predicting `household` from `al`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic regression model and store the class predictions.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "feature_cols = ['al']\n",
    "X = df.loc[:, feature_cols]\n",
    "y = df.loc[:, 'household']\n",
    "\n",
    "logreg.fit(X,y)\n",
    "pred = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the predicted class using the logistic regression as we did for the linear regression predictions above.**\n",
    "\n",
    "As you will see, the class predictions are nearly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df.plot(kind='scatter', x='al', y='household', ax=ax, grid=True)\n",
    "ax.plot(df.loc[:, 'al'], np.array(pred), c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>This is what we got just now but less work??!!!</center>\n",
    "\n",
    "<img src=\"https://static1.squarespace.com/static/58751ef6db29d6ff4a8f84b6/58751fc09de4bbe17f629c6d/59131a568419c2f417285bc2/1556913316191/catshock.jpg?format=750w\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted the predicted probabilities instead of just the class predictions, to understand how confident we are in a given prediction?\n",
    "\n",
    "**Using the built-in `.predict_proba()` function, examine the predicted probabilities for the first handful of rows of `X`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict_proba(X)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn orders the columns according to our class labels. The two-column output of `predict_proba` returns a column for each class of our `household` variable. The first column is the probability of `household=0` for a given row, and the second column is the probability of `household=1`.\n",
    "\n",
    "**Store the predicted probabilities of class=1 in its own column in the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the predicted probabilities of class 1.\n",
    "df['household_pred_prob'] = logreg.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the predicted probabilities as a line on our plot (probability of `household=1` as `al` changes).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted probabilities.\n",
    "fig, ax = plt.subplots()\n",
    "df.plot(kind='scatter', x='al', y='household', ax=ax, grid=True)\n",
    "df.plot(x='al', y='household_pred_prob', c='r', ax=ax, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine some example predictions.\n",
    "print(logreg.predict_proba([[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model\n",
    "\n",
    "accuracy_score(df.household, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "- Build a logistic regression model for `household` using two features of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic regression model and store the class predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"probability-odds-ratio-e-log-and-log-odds\"></a>\n",
    "## Understanding Logistic Regression\n",
    "---\n",
    "\n",
    "**Recall:** A coefficient in a *linear regression* model tells you how the *number* predicted by the model changes when the associated variable increases by one and all other variables remain the same.\n",
    "\n",
    "**Similarly**, A coefficient in a *logistic regression* model tells you how the *log odds* predicted by the model changes when the associated variable increases by one and all other variables remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to develop some intuitions about log odds to help us reason about our logistic regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$probability = \\frac {one\\ outcome} {all\\ outcomes}$$\n",
    "\n",
    "$$odds = \\frac {one\\ outcome} {all\\ other\\ outcomes}$$\n",
    "\n",
    "It is often useful to think of the numeric odds as a ratio. For example, 5/1 = 5 odds is \"5 to 1\" -- five wins for every one loss (e.g. of six total plays). 2/3 odds means \"2 to 3\" -- two wins for every three losses (e.g. of five total plays).\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Dice roll of 1: probability = 1/6, odds = 1/5\n",
    "- Even dice roll: probability = 3/6, odds = 3/3 = 1\n",
    "- Dice roll less than 5: probability = 4/6, odds = 4/2 = 2\n",
    "\n",
    "$$odds = \\frac {probability} {1 - probability}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As an example we can create a table of probabilities vs. odds, as seen below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a table of probability versus odds.\n",
    "table = pd.DataFrame({'probability':[0.1, 0.2, 0.25, 0.5, 0.6, 0.8, 0.9]})\n",
    "table['odds'] = table.probability / (1 - table.probability)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "Convert the following probabilities to odds:\n",
    "\n",
    "1. .25\n",
    "1. 1/3\n",
    "1. 2/3\n",
    "1. .95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"understanding-e-and-the-natural-logarithm\"></a>\n",
    "### Understanding the Natural Logarithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logarithm tells you the *order of magnitude* of a number. The base-10 logarithm is a continuous version of \"the number of times you would need to multiply 10 to get that number.\"\n",
    "\n",
    "| number | number as a power of 10 | $\\log_{10}$(number) |\n",
    "| ------ | --- | --- |\n",
    "| $1 $|$ 10^0$ | 0 |\n",
    "| $10 $|$ 10^1$ | 1 |\n",
    "| $100 $|$ 10^2$ | 2 |\n",
    "| $1000 $|$ 10^3$ | 3 |\n",
    "\n",
    "It also works in the other direction:\n",
    "\n",
    "| number | number as a power of 10 | $\\log_{10}$(number) |\n",
    "| ------ | --- | --- |\n",
    "| $.001 $ | $ 10^{-3}$ | -3 |\n",
    "| $.01 $ | $ 10^{-2}$ | -2 |\n",
    "| $.1 $|$ 10^{-1}$ | -1 |\n",
    "| $1 $|$ 10^0$ | 0 |\n",
    "\n",
    "And for numbers in between exact powers of 10:\n",
    "\n",
    "| number | number as a power of 10 | $\\log_{10}$(number) |\n",
    "| ------ | --- | --- |\n",
    "| $1$ | $ 10^{0}$ | 0 |\n",
    "| $2$ | $ 10^{.301}$ | .301 |\n",
    "| $5$|$ 10^{.699}$ | .699 |\n",
    "| $10$|$ 10^1$ | 1 |\n",
    "| $20$|$ 10^{1.301}$ | 1.301 |\n",
    "| $50$|$ 10^{1.699}$ | 1.699 |\n",
    "| $100$|$ 10^2$ | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base $e$.** It is often convenient to use the special number $e$ as a base instead of 10. The interpretation is analogous: the base-$e$ logarithm of a number is a continuous version of \"the number of times you would have to multiple $e$ to get that number.\"\n",
    "\n",
    "For instance:\n",
    "\n",
    "| number | number as a power of $e$ | $\\log_{e}$(number) |\n",
    "| ------ | --- | --- |\n",
    "| $1 $|$ e^0$ | 0 |\n",
    "| $2.718$|$ e^1$ | 1 |\n",
    "| $7.39$|$ e^2$ | 2 |\n",
    "| $20.09$|$ e^3$ | 3 |\n",
    "\n",
    "It also works in the other direction:\n",
    "\n",
    "| number | number as a power of $e$ | $\\log_{e}$(number) |\n",
    "| ------ | --- | --- |\n",
    "| $.050 $ | $ e^{-3}$ | -3 |\n",
    "| $.135 $ | $ e^{-2}$ | -2 |\n",
    "| $.368 $|$ e^{-1}$ | -1 |\n",
    "| $1 $|$ e^0$ | 0 |\n",
    "\n",
    "And for numbers in between exact powers of $e$:\n",
    "\n",
    "| number | number as a power of $e$ | $\\log_{e}$(number) |\n",
    "| ------ | --- | --- |\n",
    "| $1$ | $ e^{0}$ | 0 |\n",
    "| $1.35$ | $ e^{.301}$ | .301 |\n",
    "| $2.01$|$ e^{.699}$ | .699 |\n",
    "| $2.718$|$ e^1$ | 1 |\n",
    "| $3.67$|$ e^{1.301}$ | 1.301 |\n",
    "| $5.47$|$ e^{1.699}$ | 1.699 |\n",
    "| $7.39$|$ e^2$ | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we take the **logarithm** of an **odds** we get the **log odds**.\n",
    "\n",
    "The most common convention is to use base-$e$ logarithms unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add log odds to the table.\n",
    "table['logodds'] = np.log(table['odds'])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** log odds goes to $-\\infty$ as probability goes to 0, and goes to $\\infty$ as probability goes to 1.\n",
    "\n",
    "**Consequence:** The fact that linear model is unbounded is fine if we use it to model *log odds* rather than *probability*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-logistic-regression\"></a>\n",
    "### What Is Logistic Regression?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression:** *Continuous response* is modeled as a linear combination of the features.\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "\n",
    "**Logistic regression:** *Log odds* is modeled as a linear combination of the features.\n",
    "\n",
    "$$\\log \\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This equation can be rearranged to get the predicted probability:\n",
    "\n",
    "$$\\hat{p} = \\frac{e^{\\beta_0 + \\beta_1x}} {1 + e^{\\beta_0 + \\beta_1x}}$$\n",
    "\n",
    "This equation gives us the \"S\" (sigmoid) shape for the predicted probability as a function of $\\beta_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we interpret the regression parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression:**\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "\n",
    "- $\\beta_0$ tells you the model's prediction for $y$ when all input features are zero.\n",
    "- $\\beta_1$ tells you how the model's prediction for $y$ changes with a one-unit increase in $x$ when all other variables remain the same.\n",
    "\n",
    "**Logistic regression:**\n",
    "\n",
    "$$\\log \\left({p\\over 1-p}\\right) = \\beta_0 + \\beta_1x$$\n",
    "\n",
    "- $\\beta_0$ tells you the model's prediction for the *log odds of $y$* when all input features are zero.\n",
    "- $\\beta_1$ tells you how the model's prediction for *the log odds of* $y$ changes with a one-unit increase in $x$ when all other variables remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bottom line:** A positive coefficient means that the predicted log odds of the response (and thus the predicted probability) increases with the associated variable, while a negative coefficient means that it decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logistic regression beta values](./img/logistic_betas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the $\\beta_0$ value shifts the curve horizontally, whereas changing the $\\beta_1$ value changes the slope of the curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- Logistic regression addresses a binary classification problem by modeling the *log odds* that an individual is in the class as a linear function of the model features.\n",
    "- A coefficient in a logistic regression model tells you *how the log odds that the model predicts changes* with a one-unit increase in the associated input feature, while other features remain unchanged.\n",
    "- The model's log-odds predictions can be transformed into *probabilities*.\n",
    "- Those predicted probabilities follow an \"s\" (sigmoid) shape that is bounded by 0 and 1, as a function of the input features.\n",
    "- Those predicted probabilities can be converted into \"hard\" class predictions by mapping everything above a threshold to 1 and everything below it to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-logistic-regression-to-other-models\"></a>\n",
    "## Comparing Logistic Regression to Other Models\n",
    "---\n",
    "\n",
    "Advantages of logistic regression:\n",
    "\n",
    "- Somewhat interpretable.\n",
    "- Training and prediction are fast.\n",
    "- Outputs probabilities.\n",
    "- Features don't need scaling.\n",
    "- Can perform well with a small number of observations.\n",
    "\n",
    "Disadvantages of logistic regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the log odds of the response.\n",
    "- Performance is (generally) not competitive with the best supervised learning methods.\n",
    "- Can't automatically learn feature interactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
