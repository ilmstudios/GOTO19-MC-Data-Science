{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Classification Metrics\n",
    "\n",
    "---\n",
    "\n",
    "By default, the `.score` method of a logistic regression model in sklearn returns accuracy:\n",
    "\n",
    "$$Accuracy = \\frac{total~predicted~correct}{total~predicted}$$\n",
    "\n",
    "However, accuracy is not always the most relevant metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the **confusion matrix** for a binary classification problem where we have 165 observations/rows of people who are either smokers or nonsmokers.\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"><font color=\"blue\">TN = 50</font></td>\n",
    "    <td style=\"text-align: center\"><font color=\"red\">FP = 10</font></td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"><font color=\"orange\">FN = 5</font></td>\n",
    "    <td style=\"text-align: center\"><font color=\"green\">TP = 100</font></td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "- <font color=\"green\">**True positives (TP):**</font> These are cases in which we predicted yes (smokers), and they actually are smokers.\n",
    "- <font color=\"blue\">**True negatives (TN):**</font> We predicted no, and they are nonsmokers.\n",
    "- <font color=\"red\">**False positives (FP):**</font> We predicted yes, but they were not actually smokers. (This is also known as a \"Type I error.\")\n",
    "- <font color=\"orange\">**False negatives (FN):**</font> We predicted no, but they are smokers. (This is also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "Categorize these cases as TP, TN, FP, or FN.\n",
    "    \n",
    "- We predict that a growth is malignant, and it is benign. (is_malignant=1)\n",
    "- We predict that an image does not contain a cat, and it does not. (has_cat=1)\n",
    "- We predict that a locomotive will fail in the next two weeks, and it does. (breaks=1)\n",
    "- We predict that a user will like a song, and she does not. (likes_song=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"accuracy-true-positive-rate-and-false-negative-rate\"></a>\n",
    "### Accuracy, True Positive Rate, and False Negative Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:** Overall, how often is the classifier correct?\n",
    "\n",
    "<span>\n",
    "    (<span style=\"color: green\">TP</span>+<span style=\"color: blue\">TN</span>)/<span style=\"color: purple\">total</span> = (<span style=\"color: green\">100</span>+<span style=\"color: blue\">50</span>)/<span style=\"color: purple\">165</span> = 0.91\n",
    "</span>\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom; color: purple\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center; background-color: blue\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center; background-color: green\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True positive rate (TPR)** asks, “Out of all of the target class labels, how many were accurately predicted to belong to that class?”\n",
    "\n",
    "For example, given a medical exam that tests for cancer, how often does it correctly identify patients with cancer?\n",
    "\n",
    "<span>\n",
    "<span style=\"color: green\">TP</span>/<span style=\"color: aqua\">actual yes</span> = <span style=\"color: green\">100</span>/<span style=\"color: aqua\">105</span> = 0.95\n",
    "</span>\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center;background-color: green\">TP = 100</td>\n",
    "    <td style=\"text-align: center;color: aqua\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False positive rate (FPR)** asks, “Out of all items not belonging to a class label, how many were predicted as belonging to that target class label?”\n",
    "\n",
    "For example, given a medical exam that tests for cancer, how often does it trigger a “false alarm” by incorrectly saying a patient has cancer?\n",
    "\n",
    "<span>\n",
    "<span style=\"color: orange\">FP</span>/<span style=\"color: fuchsia\">actual no</span> = <span style=\"color: orange\">10</span>/<span style=\"color: fuchsia\">60</span> = 0.17\n",
    "</span>\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center;background-color: orange\">FP = 10</td>\n",
    "    <td style=\"text-align: center;color:fuchsia\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "We turn the probabilities output by a logistic regression model into \"hard\" predictions by setting a threshold. For instance, we might treat all probabilities above .5 as positive predictions and the rest as negative predictions.\n",
    "\n",
    "- Does the true positive rate of a logistic regression model increase or decrease if we change the threshold probability for treating a prediction as positive from .5 to .6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does the false positive rate of a logistic regression model increase or decrease if we change the threshold probability for treating a prediction as positive from .5 to .6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Describe a situation in which you would want to use a high threshold probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Describe a situation in which you would want to use a low threshold probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the accuracy, true positive rate, and false positive rate for the confusion matrix below.\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 140</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">30</td>\n",
    "    <td style=\"text-align: center\">10</td>\n",
    "    <td style=\"text-align: center\">40</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "    <td style=\"text-align: center\">40</td>\n",
    "    <td style=\"text-align: center\">100</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">90</td>\n",
    "    <td style=\"text-align: center\">50</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Intuitive: it's a lot like an exam score where you get total correct/total attempted.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Potentially misleading: Can look OK when model is just outputting the most common label.\n",
    "    - Particularly bad when classes are imbalanced -- e.g. train doesn't break 99% of the time, so a model that always says \"won't break\" has 99% accuracy -- but it fails exactly when we need it!\n",
    "- Doesn't account for relative costs of false positives and false negatives.\n",
    "- Doesn't say anything about how far predicted probabilities are from the correct labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other metrics to investigate:**\n",
    "    \n",
    "- **Classification error:** Proportion of incorrect predictions (1-accuracy, lower is better).\n",
    "- **Receiver Operating Characteristic (ROC) curves:** True positive rate vs. false positive rate across all possible threshold probabilities. The **area under the ROC curve** (AUC) is a measure of how well your model performs overall across those thresholds.\n",
    "  - Allows you to visualize the performance of your classifier across all possible classification thresholds, thus helping you to choose a threshold that appropriately balances true positives and false positives.\n",
    "  - Still useful when there is high class imbalance (unlike classification accuracy/error).\n",
    "  - Harder to use when there are more than two response classes.\n",
    "- **Log loss**: Measures how far the output probabilities are from the correct labels. (Useful when you want to make expected value calculations with those probabilities or triage cases for further attention.)\n",
    "- **True Negative Rate**, **False Negative Rate**\n",
    "- **Recall** (a.k.a. True Positive Rate), **Precision** (proportion of positive predictions that are true)\n",
    "\n",
    "These measures are all readily available in sklearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
